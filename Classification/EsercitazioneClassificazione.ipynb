{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "540091f8-c612-4f06-94e1-82651b879f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import\n",
    "from sklearn.compose import\n",
    "from sklearn.model_selection import\n",
    "from sklearn.pipeline import\n",
    "from sklearn.metrics import\n",
    "from sklearn.linear_model import\n",
    "from sklearn.svm import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3743e35e-67b3-43e0-baef-70a8d0935681",
   "metadata": {},
   "source": [
    "# Esercitazione Classificazione Binaria\n",
    "\n",
    "In questo notebook svolgeremo un esercizio in gruppi di lavoro. Si tratta di un task di classificazione binaria in ambito medico.\n",
    "\n",
    "Il dataset da utilizzare e' semplice e di dimensioni contenute. E' pubblicamente reperibile al link [https://www.kaggle.com/fedesoriano/stroke-prediction-dataset](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset). Nella cartella Classification potete trovare una copia del dataset.\n",
    "\n",
    "Il task da affrontare e' problema di classificazione binaria supervisionata, in cui la variabile da predirre e' l'avvenuto o meno ictus di un paziente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3051f-c4b5-4be0-9260-461854509c14",
   "metadata": {},
   "source": [
    "## Step 1: ETL Processing\n",
    "In questa fase il gruppo deve caricare in un DataFrame il dataset da esaminare ed identificare le colonne/feature che potrebbe richiedere una trasformazione o un preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83983595-a550-4c81-b3a3-22b649fae301",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_19160/353823556.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\matte\\AppData\\Local\\Temp/ipykernel_19160/353823556.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    stroke_dataset =\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stroke_dataset = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a1915-0a57-40ee-abce-81ae0831ad2b",
   "metadata": {},
   "source": [
    "Quale colonna del dataset utilizzo come vettore delle etichette?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afb5c1c-342a-43f5-9877-8a8761d2181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_labels = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6129ae47-d922-4e0c-ab03-8aeb72dc45fd",
   "metadata": {},
   "source": [
    "Quali sono le feature che necessitano di una trasformazione? Ci sono delle feature che vanno eliminate? Ci sono dei record che vanno eliminati?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2325d216-bd8f-4322-8a4d-cc09e3b3644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4909 entries, 0 to 5109\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             4909 non-null   object \n",
      " 1   age                4909 non-null   float64\n",
      " 2   hypertension       4909 non-null   int64  \n",
      " 3   heart_disease      4909 non-null   int64  \n",
      " 4   ever_married       4909 non-null   object \n",
      " 5   work_type          4909 non-null   object \n",
      " 6   Residence_type     4909 non-null   object \n",
      " 7   avg_glucose_level  4909 non-null   float64\n",
      " 8   bmi                4909 non-null   float64\n",
      " 9   smoking_status     4909 non-null   object \n",
      " 10  stroke             4909 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(5)\n",
      "memory usage: 460.2+ KB\n"
     ]
    }
   ],
   "source": [
    "stroke_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe2d4458-01fe-49de-a34a-84b19f4cd80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_dataset = stroke_dataset.drop(['id'], axis = 1).dropna(subset = ['bmi'],axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f31c8-8c9f-4248-84b0-1de2e42c030e",
   "metadata": {},
   "source": [
    "Ci sono delle feature di tipo categoriche? Quante sono binarie? Quante prevedono piu' di due categorie distinte?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6e0ba5b-dcc8-41ce-99a8-4846430e91ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Private          2811\n",
       "Self-employed     775\n",
       "children          671\n",
       "Govt_job          630\n",
       "Never_worked       22\n",
       "Name: work_type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessing = ColumnTransformer([\n",
    "    ('age', StandardScaler, ['age']),\n",
    "    ....\n",
    "],\n",
    "    remainder = 'passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9326145-fabc-42c9-8a00-99ace8ae59ff",
   "metadata": {},
   "source": [
    "## STEP 2: Training e Test Sets\n",
    "Dividiamo il dataset in training e test sets in modo tale che il test set contenga il 20% dei record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6bd36e-1c9d-4045-b210-a4c21021c629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d21f5e38-16be-45f7-9cec-8a0db1e51c6e",
   "metadata": {},
   "source": [
    "## STEP 3: La scelta degli algoritmi/modelli da utilizzare\n",
    "\n",
    "In questa caso utilizzeremo tre diversi modelli visti a lezione:\n",
    "- Perceptron -> [doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html)\n",
    "- LogisticRegression -> [doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "- Support Vector Machine -> [doc](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d60fb0-fe01-451a-bc7b-93f6b3655605",
   "metadata": {},
   "source": [
    "## STEP 4: cross-validation\n",
    "\n",
    "Utilizzanod 5-fold cross-validation il gruppo deve valutare le performance dei diversi modelli (la scelta degli iperparametri per ora non e' vincolata). Nel dettaglio si devono utilizzare come misure di performance:\n",
    "- accuracy\n",
    "- precision\n",
    "- recall \n",
    "- f1-score\n",
    "\n",
    "Per ogni modello si deve costruire la distribuzione della misura di performance (un box plot e' sufficiente), oppure calcolare media e deviazione standard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f3336-f376-4e0b-b9aa-9c533a0b4a73",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
